#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Subsection
Data Pre-processing
\end_layout

\begin_layout Standard
To extract relevant features from the images preprocessing is necessary.
 To do so, a pre-processing pipeline comprising of three steps was created.
\end_layout

\begin_layout Paragraph*
Sharpest Image:
\end_layout

\begin_layout Standard
Each image stack consists between around 10 to 20 photographs of the same
 part of one worm.
 The images in a stack differ are taken at different focal planes of the
 microscope.
 In most of the cases only one of these images shows the mitochondria in
 a sharp and clear way that can be used for classification.
 The usual process is to look at each of the images in the stack, select
 the sharpest and proceed with the next classification tasks only with the
 sharpest image.
 If a program is to be able to classify the mitochondria automatically,
 it should be able to select the sharpest image automatically as well.
 
\end_layout

\begin_layout Standard
For this purpose a simple gradient based estimation function is used.
 The grayscale image is represented by the matrix 
\begin_inset Formula $I\subseteq{\mathbb{N}}^{m\times n}$
\end_inset

 with values in the range 
\begin_inset Formula $[0,255]$
\end_inset

 with 0 for black and 255 for white pixels.
 The sum over the gradients 
\begin_inset Formula $I_{x}$
\end_inset

 and 
\begin_inset Formula $I_{y}$
\end_inset

 in both image dimensions 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $y$
\end_inset

 normalized by the number of gradients gives a good estimation on how sharp
 a photograph actually is.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
I_{x}=\frac{\partial I}{\partial x}\qquad I_{y}=\frac{\partial I}{\partial y}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
s=\frac{\sum_{i=1}^{m}\sum_{j=1}^{n}S_{ij}}{mn}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
S_{ij}=\sqrt{({{I_{x}}_{ij}}^{2}+{{I_{y}}_{ij}}^{2})}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The higher the value 
\begin_inset Formula $s$
\end_inset

 the sharper the image.
 A disadvantage of this simple method is that, one usually can only compare
 images showing the same motif.
 Hence, in real image processing software much better methods for estimating
 image sharpness are in use.
 Nevertheless it has proved itself to be a sufficient method for the purpose
 of classification presented in this report.
 This is because only images within a single stack are compared, and they
 all show the exact same photograph.
\end_layout

\begin_layout Paragraph
Histogram Analysis:
\end_layout

\begin_layout Standard
To adjust the optimal contrast of each image it is necessary to have a look
 at the histograms and how the different levels (0 to 255) of gray are distribut
ed all over one image.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/c1_o.tif
	scale 20
	special width=\columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Fragmented mitochondria
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/l1_o.tif
	special width=\columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Tubular mitochondria
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The task is to find suitable values for 
\begin_inset Formula $b_{l}$
\end_inset

, the lower bound, below which everything goes to 0 (black) and 
\begin_inset Formula $b_{u}$
\end_inset

, the upper bound, above which everything goes to 255 (white).
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f_{l}(l)=\sum_{i=1}^{l}h_{i}\leq\beta\sum_{i=1}^{256}h_{i}
\end{equation}

\end_inset


\begin_inset Formula 
\begin{equation}
f_{u}(u)=\sum_{i=1}^{u}h_{256-i+1}\leq\alpha\sum_{i=1}^{256}h_{i}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
1\leq l\leq256\qquad1\leq u\leq256
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
b_{l}=\frac{\mbox{argmax}_{b}(f_{b})}{256}\qquad b_{u}=\frac{\mbox{argmax}_{u}(f_{u})}{256}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\alpha+\beta\leq1
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The gray scale levels in between are scaled to fit into the histogram of
 the output image.
 The result is a high contrast image in which mitochondria are much easier
 to find.
 Because all the images have different histograms, it is not possible to
 use the same lower bound and upper bound for all of them.
 So the variables 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 were defined, corresponding to how many of the pixels should have the grayscale
 value of 0 (black) or 255 (white) after the adjustment.
 Using this procedure the optimal bounds for each individual image were
 found.
 The performance of the later classification process depends highly on the
 quality of output of this contrast adjustment.
 In order to find the best values for 
\begin_inset Formula $\alpha$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

 we used the optimization tools of MATLAB.
 Misclassification rate on the training set is used as the optimization
 objective.
\end_layout

\begin_layout Paragraph
Boundaries and Blob Detection:
\end_layout

\begin_layout Standard
After improving the contrast of each image it can easily be converted to
 a binary image in that the mitochondria can be found as white areas.
 Using the MatLab function '
\shape italic
\size footnotesize
bwboundaries
\shape default
\size default
' it was possible trace the exterior boundaries of the mitochondria in the
 binary image.
 After filtering out objects that are too big or too small to be valid mitochond
ria a set of vectors were generated, each containing the borders of one
 of the mitochondrion.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/c1_m.eps
	special width=\columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Detected fragmented mitochondria
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename images/l1_m.eps
	special width= \columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Detected tubular mitochondria
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Feature extraction
\begin_inset CommandInset label
LatexCommand label
name "sub:Feature-extraction"

\end_inset


\end_layout

\begin_layout Paragraph
Circularity:
\end_layout

\begin_layout Standard
The circularity of mitochondria is one of the most important and reasonable
 ways to compare mitochondria in tubular and fragmented cells.
 If the cell is classified as 
\shape italic
tubular
\shape default
, the bounds of each mitochondrion are far from being circularly dirtibuted
 whereas in a fragmented classified cell almost all of the mitochondria
 are indeed shaped like circles.
\end_layout

\begin_layout Standard
Since the boundaries have already been found in an earlier pre-processing
 step, FuzzyCShells 
\begin_inset CommandInset citation
LatexCommand cite
key "R2010"

\end_inset

 method was used to calculate the error that represents the average of the
 distance between the points and the circle.
 The centre of the circle is the mean 
\begin_inset Formula $\mu$
\end_inset

 of the data set of size 
\begin_inset Formula $N$
\end_inset

.
 The radius 
\begin_inset Formula $r$
\end_inset

 giving the smalles error can be calculated in one step, too.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r=\frac{\sum_{i=1}^{N}\|x_{i}-\mu\|}{N}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The distance between each of the data points and the circle is given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
d(x_{i},(\mu,r))=|\|x_{i}-\mu\|-r|.
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The error value to compare the circularity is then given by the sum over
 all distances 
\begin_inset Formula $d(x_{i},(\mu,r))$
\end_inset

 between the data points 
\begin_inset Formula $x_{i}$
\end_inset

 and the circle normalized by the number of data points 
\begin_inset Formula $N$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
e_{c}=\frac{\sum_{i=1}^{N}d(x_{i},(\mu,r))}{N}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
An error 
\begin_inset Formula $e_{c}=0$
\end_inset

 means that the blob detected is perfectly shaped like a circle.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/boundary_circle_1.eps
	special width=\columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Circular distributed boundary of a blob
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/boundary_line_2.eps
	special width=\columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Tubuar shaped boundary of a blob
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Covariance Analysis:
\end_layout

\begin_layout Standard
The covariance analysis is yet another way to generate a feature based on
 the shape of a blob.
 If data points are distributed in a tubular fashion, then the covariance
 of the points has two very different values for the covariance's eigenvalues
 
\begin_inset Formula $\lambda_{b}$
\end_inset

 and 
\begin_inset Formula $\lambda_{s}$
\end_inset

, where 
\begin_inset Formula $\lambda_{b}\geqslant\lambda_{s}$
\end_inset

.
 The biggest eigenvalue 
\begin_inset Formula $\lambda_{b}$
\end_inset

 will belong to the eigenvector pointing in the direction along which the
 original blob data is distributed.
 So the ratio of the two eigen values, 
\begin_inset Formula $e_{\lambda}$
\end_inset

, is close to zero if the data is distributed as a line.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
e_{\lambda}=\lambda_{b}/\lambda_{s}
\end{equation}

\end_inset


\end_layout

\begin_layout Paragraph
Thumbnail Features:
\begin_inset CommandInset label
LatexCommand label
name "par:Thumbnail-Features"

\end_inset


\end_layout

\begin_layout Standard
After blob detection, the ratio of the eigenvalues and the circularity measure
 were passed as input to various classification algorithms as shown in figure
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:classification-pipeline"

\end_inset

.
 Note that features for neural network is slightly different from the rest
 of classification methods.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
vskip
\end_layout

\end_inset

 0.2in
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename images/Pipeline.png
	special width=\columnwidth

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Overview of the classification pipeline
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:classification-pipeline"

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
vskip
\end_layout

\end_inset

-0.2in
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For neural network (only) the blobs have been used directly to train the
 model and make predictions.
 Instead of computing 
\begin_inset Formula $e_{c}$
\end_inset

 and 
\begin_inset Formula $e_{\lambda}$
\end_inset

 for each blob and using these values as features for classification, the
 pixel values of the blob are used directly to make predictions.
 After blobs are detected, each blob is resized to fit into a 20
\begin_inset Formula $\times$
\end_inset

20px image.
 The blobs are then centered in the image.
 A binary image is created by filling the blob with grayscale value of 255
 (white) and that for rest of the image is set to 0 (black).
 Vectorizing these single blob images produces a 400 dimensional feature
 space that is then used to train a neural network and make predictions.
\end_layout

\end_body
\end_document
